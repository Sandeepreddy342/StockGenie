{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47d12289-8ec7-4676-8bcf-18e7b6a7d1c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea0820ae-cc6a-4424-88b1-8a7829ff5524",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\n",
    "    service_name='s3',\n",
    "    region_name='us-east-1',\n",
    "    aws_access_key_id='AKIAQ3EGRFSRWFWH6UUU',\n",
    "    aws_secret_access_key='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'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c8cf483-cd48-49dc-80fb-66e2a3e58e24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datag8080\nsandepdemo\n"
     ]
    }
   ],
   "source": [
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7b4e406-f9a1-4390-b1bc-1b0b97bba7a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = 'us-east-2'\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = 'AKIAQ3EGRFSRWFWH6UUU'\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d08cff35-bb2e-4906-be68-d680d6ef2d89",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "obj = s3.Bucket('datag8080').Object('fundamentals.csv').get()\n",
    "df = pd.read_csv(obj['Body'], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93081085-225d-4e2f-8582-e1a9fd2b1771",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'datag8080'\n",
    "key = 'config.json'\n",
    "\n",
    "obj = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "config_str = obj[\"Body\"].read().decode(\"utf-8\")\n",
    "config = json.loads(config_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93f34910-a94d-4be8-9207-5714ac91c82c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'project_info': {'name': 'My Project', 'version': 1.0}, 'source': {'type': 's3', 'bucket': 'datag8080', 'key': 'datag8080/demo'}, 'dimensions': ['Ticker Symbol'], 'depth': 1, 'filter_values': {'Ticker Symbol': 'AAPL'}, 'granularity': 'D', 'kpis': [{'name': 'average_accounts_receivable', 'sql': 'Accounts Receivable'}, {'name': 'net_income_growth', 'sql': 'Net Income'}, {'name': 'profit_margin', 'sql': 'Net Income', 'divisor': 'Total Revenue'}]}\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "531e2f90-dced-4086-b18c-1537ec14b0a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9735b7a5-4c8b-4a15-a7c1-19a3a0fc790f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[8]: <bound method IndexOpsMixin.nunique of 0        AAL\n1        AAL\n2        AAL\n3        AAL\n4        AAP\n        ... \n1776    ZION\n1777     ZTS\n1778     ZTS\n1779     ZTS\n1780     ZTS\nName: Ticker Symbol, Length: 1781, dtype: object>"
     ]
    }
   ],
   "source": [
    "df['Ticker Symbol'].nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "960a2952-090d-4291-9afa-fb358e4d7814",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker Symbol</th>\n",
       "      <th>Period Ending</th>\n",
       "      <th>Accounts Payable</th>\n",
       "      <th>Accounts Receivable</th>\n",
       "      <th>Add'l income/expense items</th>\n",
       "      <th>After Tax ROE</th>\n",
       "      <th>Capital Expenditures</th>\n",
       "      <th>Capital Surplus</th>\n",
       "      <th>Cash Ratio</th>\n",
       "      <th>Cash and Cash Equivalents</th>\n",
       "      <th>...</th>\n",
       "      <th>Total Current Assets</th>\n",
       "      <th>Total Current Liabilities</th>\n",
       "      <th>Total Equity</th>\n",
       "      <th>Total Liabilities</th>\n",
       "      <th>Total Liabilities &amp; Equity</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>Treasury Stock</th>\n",
       "      <th>For Year</th>\n",
       "      <th>Earnings Per Share</th>\n",
       "      <th>Estimated Shares Outstanding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>3.068000e+09</td>\n",
       "      <td>-222000000.0</td>\n",
       "      <td>-1.961000e+09</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-1.888000e+09</td>\n",
       "      <td>4.695000e+09</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.330000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>7.072000e+09</td>\n",
       "      <td>9.011000e+09</td>\n",
       "      <td>-7.987000e+09</td>\n",
       "      <td>2.489100e+10</td>\n",
       "      <td>1.690400e+10</td>\n",
       "      <td>2.485500e+10</td>\n",
       "      <td>-367000000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>-5.60</td>\n",
       "      <td>3.350000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>4.975000e+09</td>\n",
       "      <td>-93000000.0</td>\n",
       "      <td>-2.723000e+09</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-3.114000e+09</td>\n",
       "      <td>1.059200e+10</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.175000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.432300e+10</td>\n",
       "      <td>1.380600e+10</td>\n",
       "      <td>-2.731000e+09</td>\n",
       "      <td>4.500900e+10</td>\n",
       "      <td>4.227800e+10</td>\n",
       "      <td>2.674300e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>-11.25</td>\n",
       "      <td>1.630222e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>4.668000e+09</td>\n",
       "      <td>-160000000.0</td>\n",
       "      <td>-1.500000e+08</td>\n",
       "      <td>143.0</td>\n",
       "      <td>-5.311000e+09</td>\n",
       "      <td>1.513500e+10</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.768000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.175000e+10</td>\n",
       "      <td>1.340400e+10</td>\n",
       "      <td>2.021000e+09</td>\n",
       "      <td>4.120400e+10</td>\n",
       "      <td>4.322500e+10</td>\n",
       "      <td>4.265000e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>4.02</td>\n",
       "      <td>7.169154e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>5.102000e+09</td>\n",
       "      <td>352000000.0</td>\n",
       "      <td>-7.080000e+08</td>\n",
       "      <td>135.0</td>\n",
       "      <td>-6.151000e+09</td>\n",
       "      <td>1.159100e+10</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.085000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>9.985000e+09</td>\n",
       "      <td>1.360500e+10</td>\n",
       "      <td>5.635000e+09</td>\n",
       "      <td>4.278000e+10</td>\n",
       "      <td>4.841500e+10</td>\n",
       "      <td>4.099000e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>11.39</td>\n",
       "      <td>6.681299e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAP</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>2.409453e+09</td>\n",
       "      <td>-89482000.0</td>\n",
       "      <td>6.000000e+05</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-2.711820e+08</td>\n",
       "      <td>5.202150e+08</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.981110e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>3.184200e+09</td>\n",
       "      <td>2.559638e+09</td>\n",
       "      <td>1.210694e+09</td>\n",
       "      <td>3.403120e+09</td>\n",
       "      <td>4.613814e+09</td>\n",
       "      <td>6.205003e+09</td>\n",
       "      <td>-27095000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.29</td>\n",
       "      <td>7.328355e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>ZION</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.530000e+06</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.573610e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.576313e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.507519e+09</td>\n",
       "      <td>5.216201e+10</td>\n",
       "      <td>5.966952e+10</td>\n",
       "      <td>2.210591e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>2.578925e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>1.381000e+09</td>\n",
       "      <td>-99000000.0</td>\n",
       "      <td>9.000000e+06</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-1.840000e+08</td>\n",
       "      <td>8.780000e+08</td>\n",
       "      <td>43.0</td>\n",
       "      <td>6.100000e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>3.357000e+09</td>\n",
       "      <td>1.415000e+09</td>\n",
       "      <td>9.400000e+08</td>\n",
       "      <td>5.618000e+09</td>\n",
       "      <td>6.558000e+09</td>\n",
       "      <td>4.561000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>4.990099e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>1.071000e+09</td>\n",
       "      <td>69000000.0</td>\n",
       "      <td>-7.000000e+06</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-1.800000e+08</td>\n",
       "      <td>9.580000e+08</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8.820000e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>3.465000e+09</td>\n",
       "      <td>1.086000e+09</td>\n",
       "      <td>1.311000e+09</td>\n",
       "      <td>5.277000e+09</td>\n",
       "      <td>6.588000e+09</td>\n",
       "      <td>4.785000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>5.025862e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>1.313000e+09</td>\n",
       "      <td>-58000000.0</td>\n",
       "      <td>-8.100000e+07</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-2.240000e+08</td>\n",
       "      <td>1.012000e+09</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.154000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>3.830000e+09</td>\n",
       "      <td>1.781000e+09</td>\n",
       "      <td>1.068000e+09</td>\n",
       "      <td>6.845000e+09</td>\n",
       "      <td>7.913000e+09</td>\n",
       "      <td>4.765000e+09</td>\n",
       "      <td>-203000000.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>4.985294e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>1.076000e+09</td>\n",
       "      <td>15000000.0</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-2.160000e+08</td>\n",
       "      <td>1.024000e+09</td>\n",
       "      <td>65.0</td>\n",
       "      <td>7.270000e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>3.390000e+09</td>\n",
       "      <td>1.117000e+09</td>\n",
       "      <td>1.487000e+09</td>\n",
       "      <td>6.162000e+09</td>\n",
       "      <td>7.649000e+09</td>\n",
       "      <td>4.888000e+09</td>\n",
       "      <td>-421000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1781 rows × 78 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Ticker Symbol</th>\n      <th>Period Ending</th>\n      <th>Accounts Payable</th>\n      <th>Accounts Receivable</th>\n      <th>Add'l income/expense items</th>\n      <th>After Tax ROE</th>\n      <th>Capital Expenditures</th>\n      <th>Capital Surplus</th>\n      <th>Cash Ratio</th>\n      <th>Cash and Cash Equivalents</th>\n      <th>...</th>\n      <th>Total Current Assets</th>\n      <th>Total Current Liabilities</th>\n      <th>Total Equity</th>\n      <th>Total Liabilities</th>\n      <th>Total Liabilities &amp; Equity</th>\n      <th>Total Revenue</th>\n      <th>Treasury Stock</th>\n      <th>For Year</th>\n      <th>Earnings Per Share</th>\n      <th>Estimated Shares Outstanding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAL</td>\n      <td>2012-12-31</td>\n      <td>3.068000e+09</td>\n      <td>-222000000.0</td>\n      <td>-1.961000e+09</td>\n      <td>23.0</td>\n      <td>-1.888000e+09</td>\n      <td>4.695000e+09</td>\n      <td>53.0</td>\n      <td>1.330000e+09</td>\n      <td>...</td>\n      <td>7.072000e+09</td>\n      <td>9.011000e+09</td>\n      <td>-7.987000e+09</td>\n      <td>2.489100e+10</td>\n      <td>1.690400e+10</td>\n      <td>2.485500e+10</td>\n      <td>-367000000.0</td>\n      <td>2012.0</td>\n      <td>-5.60</td>\n      <td>3.350000e+08</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAL</td>\n      <td>2013-12-31</td>\n      <td>4.975000e+09</td>\n      <td>-93000000.0</td>\n      <td>-2.723000e+09</td>\n      <td>67.0</td>\n      <td>-3.114000e+09</td>\n      <td>1.059200e+10</td>\n      <td>75.0</td>\n      <td>2.175000e+09</td>\n      <td>...</td>\n      <td>1.432300e+10</td>\n      <td>1.380600e+10</td>\n      <td>-2.731000e+09</td>\n      <td>4.500900e+10</td>\n      <td>4.227800e+10</td>\n      <td>2.674300e+10</td>\n      <td>0.0</td>\n      <td>2013.0</td>\n      <td>-11.25</td>\n      <td>1.630222e+08</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAL</td>\n      <td>2014-12-31</td>\n      <td>4.668000e+09</td>\n      <td>-160000000.0</td>\n      <td>-1.500000e+08</td>\n      <td>143.0</td>\n      <td>-5.311000e+09</td>\n      <td>1.513500e+10</td>\n      <td>60.0</td>\n      <td>1.768000e+09</td>\n      <td>...</td>\n      <td>1.175000e+10</td>\n      <td>1.340400e+10</td>\n      <td>2.021000e+09</td>\n      <td>4.120400e+10</td>\n      <td>4.322500e+10</td>\n      <td>4.265000e+10</td>\n      <td>0.0</td>\n      <td>2014.0</td>\n      <td>4.02</td>\n      <td>7.169154e+08</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAL</td>\n      <td>2015-12-31</td>\n      <td>5.102000e+09</td>\n      <td>352000000.0</td>\n      <td>-7.080000e+08</td>\n      <td>135.0</td>\n      <td>-6.151000e+09</td>\n      <td>1.159100e+10</td>\n      <td>51.0</td>\n      <td>1.085000e+09</td>\n      <td>...</td>\n      <td>9.985000e+09</td>\n      <td>1.360500e+10</td>\n      <td>5.635000e+09</td>\n      <td>4.278000e+10</td>\n      <td>4.841500e+10</td>\n      <td>4.099000e+10</td>\n      <td>0.0</td>\n      <td>2015.0</td>\n      <td>11.39</td>\n      <td>6.681299e+08</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAP</td>\n      <td>2012-12-29</td>\n      <td>2.409453e+09</td>\n      <td>-89482000.0</td>\n      <td>6.000000e+05</td>\n      <td>32.0</td>\n      <td>-2.711820e+08</td>\n      <td>5.202150e+08</td>\n      <td>23.0</td>\n      <td>5.981110e+08</td>\n      <td>...</td>\n      <td>3.184200e+09</td>\n      <td>2.559638e+09</td>\n      <td>1.210694e+09</td>\n      <td>3.403120e+09</td>\n      <td>4.613814e+09</td>\n      <td>6.205003e+09</td>\n      <td>-27095000.0</td>\n      <td>2012.0</td>\n      <td>5.29</td>\n      <td>7.328355e+07</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1776</th>\n      <td>ZION</td>\n      <td>2015-12-31</td>\n      <td>0.000000e+00</td>\n      <td>0.0</td>\n      <td>-2.530000e+06</td>\n      <td>4.0</td>\n      <td>-1.573610e+08</td>\n      <td>0.000000e+00</td>\n      <td>0.0</td>\n      <td>1.576313e+10</td>\n      <td>...</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>7.507519e+09</td>\n      <td>5.216201e+10</td>\n      <td>5.966952e+10</td>\n      <td>2.210591e+09</td>\n      <td>0.0</td>\n      <td>2015.0</td>\n      <td>1.20</td>\n      <td>2.578925e+08</td>\n    </tr>\n    <tr>\n      <th>1777</th>\n      <td>ZTS</td>\n      <td>2013-12-31</td>\n      <td>1.381000e+09</td>\n      <td>-99000000.0</td>\n      <td>9.000000e+06</td>\n      <td>54.0</td>\n      <td>-1.840000e+08</td>\n      <td>8.780000e+08</td>\n      <td>43.0</td>\n      <td>6.100000e+08</td>\n      <td>...</td>\n      <td>3.357000e+09</td>\n      <td>1.415000e+09</td>\n      <td>9.400000e+08</td>\n      <td>5.618000e+09</td>\n      <td>6.558000e+09</td>\n      <td>4.561000e+09</td>\n      <td>0.0</td>\n      <td>2013.0</td>\n      <td>1.01</td>\n      <td>4.990099e+08</td>\n    </tr>\n    <tr>\n      <th>1778</th>\n      <td>ZTS</td>\n      <td>2014-12-31</td>\n      <td>1.071000e+09</td>\n      <td>69000000.0</td>\n      <td>-7.000000e+06</td>\n      <td>44.0</td>\n      <td>-1.800000e+08</td>\n      <td>9.580000e+08</td>\n      <td>81.0</td>\n      <td>8.820000e+08</td>\n      <td>...</td>\n      <td>3.465000e+09</td>\n      <td>1.086000e+09</td>\n      <td>1.311000e+09</td>\n      <td>5.277000e+09</td>\n      <td>6.588000e+09</td>\n      <td>4.785000e+09</td>\n      <td>0.0</td>\n      <td>2014.0</td>\n      <td>1.16</td>\n      <td>5.025862e+08</td>\n    </tr>\n    <tr>\n      <th>1779</th>\n      <td>ZTS</td>\n      <td>2015-12-31</td>\n      <td>1.313000e+09</td>\n      <td>-58000000.0</td>\n      <td>-8.100000e+07</td>\n      <td>32.0</td>\n      <td>-2.240000e+08</td>\n      <td>1.012000e+09</td>\n      <td>65.0</td>\n      <td>1.154000e+09</td>\n      <td>...</td>\n      <td>3.830000e+09</td>\n      <td>1.781000e+09</td>\n      <td>1.068000e+09</td>\n      <td>6.845000e+09</td>\n      <td>7.913000e+09</td>\n      <td>4.765000e+09</td>\n      <td>-203000000.0</td>\n      <td>2015.0</td>\n      <td>0.68</td>\n      <td>4.985294e+08</td>\n    </tr>\n    <tr>\n      <th>1780</th>\n      <td>ZTS</td>\n      <td>2016-12-31</td>\n      <td>1.076000e+09</td>\n      <td>15000000.0</td>\n      <td>2.000000e+06</td>\n      <td>55.0</td>\n      <td>-2.160000e+08</td>\n      <td>1.024000e+09</td>\n      <td>65.0</td>\n      <td>7.270000e+08</td>\n      <td>...</td>\n      <td>3.390000e+09</td>\n      <td>1.117000e+09</td>\n      <td>1.487000e+09</td>\n      <td>6.162000e+09</td>\n      <td>7.649000e+09</td>\n      <td>4.888000e+09</td>\n      <td>-421000000.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000000e+00</td>\n    </tr>\n  </tbody>\n</table>\n<p>1781 rows × 78 columns</p>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.fillna(0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3337794-ccdd-4260-a7e6-848abe7c125f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf07e8d1-2b5f-47cb-8e1f-ae87773bf81e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_dimension_cuts(df, dimensions, depth):\n",
    "    combinations = []\n",
    "    for i in range(1, depth + 1):\n",
    "        for combo in itertools.combinations(dimensions, i):\n",
    "            combinations.append(combo)\n",
    "    return combinations\n",
    "\n",
    "def transform_data(df, config):\n",
    "    cuts = generate_dimension_cuts(df, config['dimensions'], config['depth'])\n",
    "    time_series_data = []\n",
    "\n",
    "    for cut in cuts:\n",
    "        filtered_df = df.copy()\n",
    "        for dim in cut:\n",
    "            filter_value = config['filter_values'].get(dim)\n",
    "            if filter_value:\n",
    "                filtered_df = filtered_df[filtered_df[dim] == filter_value]\n",
    "\n",
    "        filtered_df.set_index('Period Ending', inplace=True)\n",
    "\n",
    "        for kpi in config['kpis']:\n",
    "            kpi_name = kpi['name']\n",
    "            calculation = kpi['sql']\n",
    "            divisor = kpi.get('divisor')  # Handle optional divisor\n",
    "\n",
    "            if divisor:  # Calculate percentage using mean for both elements\n",
    "                # Ensure individual column means are used for division to avoid GroupBy object errors\n",
    "                  time_series = round((filtered_df.resample(config['granularity'])[calculation].mean() /\n",
    "\n",
    "                                filtered_df.resample(config['granularity'])[divisor].mean() ),0)\n",
    "            else:\n",
    "                time_series = round(filtered_df.resample(config['granularity'])[calculation].mean(),0)\n",
    "\n",
    "            for timestamp, value in time_series.items():\n",
    "                time_series_data.append({\n",
    "                    'timestamp': timestamp.to_pydatetime(),\n",
    "                    'dimensions': list(cut),\n",
    "                    'metric': kpi_name,\n",
    "                    'value': value\n",
    "                })\n",
    "\n",
    "    return time_series_data\n",
    "\n",
    "# Preprocessing\n",
    "df['Period Ending'] = pd.to_datetime(df['Period Ending'])  # Ensure correct type\n",
    "\n",
    "transformed_data = transform_data(df, config)\n",
    "\n",
    "# Output Handling (Database update or other)\n",
    "output_df = pd.DataFrame(transformed_data)  # Example: Convert for database\n",
    "# ... Your database update logic using output_df ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42672478-1664-4c8f-8cf1-c1658508e5dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output_df=output_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "036dfca4-1f35-4b6e-9bc0-60dccfe743ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['average_accounts_receivable' 'net_income_growth' 'profit_margin']\n"
     ]
    }
   ],
   "source": [
    "print(output_df['metric'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6797f1e6-e184-41e3-9795-c7d35b7431af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output_df =  output_df.sort_values('timestamp', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d94bb4a8-3b3d-4f82-964e-d9003abbcaac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-3459378884338946>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mairflow\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DAG\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mairflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moperators\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PythonOperator\n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msqlalchemy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m create_engine\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/dbruntime/PythonPackageImportsInstrumentation/__init__.py:171\u001B[0m, in \u001B[0;36m_create_import_patch.<locals>.import_patch\u001B[0;34m(name, globals, locals, fromlist, level)\u001B[0m\n",
       "\u001B[1;32m    166\u001B[0m thread_local\u001B[38;5;241m.\u001B[39m_nest_level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
       "\u001B[1;32m    168\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[1;32m    169\u001B[0m     \u001B[38;5;66;03m# Import the desired module. If you’re seeing this while debugging a failed import,\u001B[39;00m\n",
       "\u001B[1;32m    170\u001B[0m     \u001B[38;5;66;03m# look at preceding stack frames for relevant error information.\u001B[39;00m\n",
       "\u001B[0;32m--> 171\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m \u001B[43mpython_builtin_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlocals\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfromlist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    173\u001B[0m     is_root_import \u001B[38;5;241m=\u001B[39m thread_local\u001B[38;5;241m.\u001B[39m_nest_level \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
       "\u001B[1;32m    174\u001B[0m     \u001B[38;5;66;03m# `level` represents the number of leading dots in a relative import statement.\u001B[39;00m\n",
       "\u001B[1;32m    175\u001B[0m     \u001B[38;5;66;03m# If it's zero, then this is an absolute import.\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'airflow'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)\nFile \u001B[0;32m<command-3459378884338946>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mairflow\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DAG\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mairflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moperators\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PythonOperator\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msqlalchemy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m create_engine\n\nFile \u001B[0;32m/databricks/python_shell/dbruntime/PythonPackageImportsInstrumentation/__init__.py:171\u001B[0m, in \u001B[0;36m_create_import_patch.<locals>.import_patch\u001B[0;34m(name, globals, locals, fromlist, level)\u001B[0m\n\u001B[1;32m    166\u001B[0m thread_local\u001B[38;5;241m.\u001B[39m_nest_level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    169\u001B[0m     \u001B[38;5;66;03m# Import the desired module. If you’re seeing this while debugging a failed import,\u001B[39;00m\n\u001B[1;32m    170\u001B[0m     \u001B[38;5;66;03m# look at preceding stack frames for relevant error information.\u001B[39;00m\n\u001B[0;32m--> 171\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m \u001B[43mpython_builtin_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlocals\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfromlist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    173\u001B[0m     is_root_import \u001B[38;5;241m=\u001B[39m thread_local\u001B[38;5;241m.\u001B[39m_nest_level \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    174\u001B[0m     \u001B[38;5;66;03m# `level` represents the number of leading dots in a relative import statement.\u001B[39;00m\n\u001B[1;32m    175\u001B[0m     \u001B[38;5;66;03m# If it's zero, then this is an absolute import.\u001B[39;00m\n\n\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'airflow'",
       "errorSummary": "<span class='ansi-red-fg'>ModuleNotFoundError</span>: No module named 'airflow'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Define your data transformation function\n",
    "def transform_data(df, config):\n",
    "    # ... Your existing `transform_data` function implementation ...\n",
    "\n",
    "    return time_series_data\n",
    "\n",
    "# Define your database update function with error handling\n",
    "def update_database(data, engine):\n",
    "    \"\"\"\n",
    "    Updates the database with transformed data, handling potential errors.\n",
    "\n",
    "    Args:\n",
    "        data (list): List of dictionaries containing transformed data.\n",
    "        engine (sqlalchemy.engine.Engine): SQLAlchemy engine for database connection.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Convert data to a pandas DataFrame and set primary key if needed\n",
    "        df = pd.DataFrame(data)\n",
    "        if \"timestamp\" in df.columns:  # Assuming timestamp is the primary key\n",
    "            df.set_index(\"timestamp\", inplace=True)\n",
    "\n",
    "        # Load data to the database table\n",
    "        df.to_sql(\"your_table_name\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle potential errors (e.g., logging, retry mechanisms)\n",
    "        print(f\"Error updating database: {e}\")\n",
    "\n",
    "# Replace with your configuration details\n",
    "default_args = {\n",
    "    \"owner\": \"airflow\",\n",
    "    \"depends_on_past\": False,  # Adjust if previous tasks are dependencies\n",
    "    \"start_date\": datetime(2024, 2, 29),  # Adjust to your desired start date\n",
    "    \"retries\": 3,  # Define number of retries for failed tasks\n",
    "    \"retry_delay\": timedelta(minutes=5),  # Set delay between retries\n",
    "}\n",
    "\n",
    "with DAG(\n",
    "    dag_id=\"transform_and_load_to_db\",\n",
    "    default_args=default_args,\n",
    "    schedule_interval=\"@daily\",  # Adjust schedule as needed\n",
    ") as dag:\n",
    "\n",
    "    # Task to transform data\n",
    "    transform_data_task = PythonOperator(\n",
    "        task_id=\"transform_data\",\n",
    "        python_callable=transform_data,\n",
    "        op_args={\"df\": df, \"config\": config},  # Pass data and configuration as arguments\n",
    "    )\n",
    "\n",
    "    # Task to update database with error handling\n",
    "    update_database_task = PythonOperator(\n",
    "        task_id=\"update_database\",\n",
    "        python_callable=update_database,\n",
    "        op_args={\n",
    "            \"data\": transform_data_task.xcom_pull(key=\"return_value\"),\n",
    "            \"engine\": create_engine(\"your_database_connection_string\"),  # Replace with your connection details\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Set task dependencies\n",
    "    transform_data_task >> update_database_task\n",
    "\n",
    "# Additional considerations:\n",
    "# - Replace placeholders with your actual values (database connection details, table name, error handling logic).\n",
    "# - Ensure your `df` and `config` variables are defined and available inside the Airflow environment.\n",
    "# - Consider using environment variables or a secrets manager to securely store sensitive information like database credentials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16b4308b-cacb-4074-b5fd-349972e6c715",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>dimensions</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-09-28</td>\n",
       "      <td>[Ticker Symbol]</td>\n",
       "      <td>average_accounts_receivable</td>\n",
       "      <td>-1.949000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>2013-09-28</td>\n",
       "      <td>[Ticker Symbol]</td>\n",
       "      <td>net_income_growth</td>\n",
       "      <td>3.703700e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>2013-09-28</td>\n",
       "      <td>[Ticker Symbol]</td>\n",
       "      <td>profit_margin</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2014-09-27</td>\n",
       "      <td>[Ticker Symbol]</td>\n",
       "      <td>average_accounts_receivable</td>\n",
       "      <td>-6.452000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2014-09-27</td>\n",
       "      <td>[Ticker Symbol]</td>\n",
       "      <td>net_income_growth</td>\n",
       "      <td>3.951000e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>dimensions</th>\n      <th>metric</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2013-09-28</td>\n      <td>[Ticker Symbol]</td>\n      <td>average_accounts_receivable</td>\n      <td>-1.949000e+09</td>\n    </tr>\n    <tr>\n      <th>1093</th>\n      <td>2013-09-28</td>\n      <td>[Ticker Symbol]</td>\n      <td>net_income_growth</td>\n      <td>3.703700e+10</td>\n    </tr>\n    <tr>\n      <th>2186</th>\n      <td>2013-09-28</td>\n      <td>[Ticker Symbol]</td>\n      <td>profit_margin</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>364</th>\n      <td>2014-09-27</td>\n      <td>[Ticker Symbol]</td>\n      <td>average_accounts_receivable</td>\n      <td>-6.452000e+09</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>2014-09-27</td>\n      <td>[Ticker Symbol]</td>\n      <td>net_income_growth</td>\n      <td>3.951000e+10</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f36c50e-c3fb-430e-9d46-9fae9ef24016",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting apache-airflow[databricks]\r\n  Cloning git://github.com/databricks/incubator-airflow.git (to revision 1.8.1-db1) to /tmp/pip-install-rzbcv98q/apache-airflow_ffd1cf4f1898401783069c3840c181fd\r\n  Running command git clone -q git://github.com/databricks/incubator-airflow.git /tmp/pip-install-rzbcv98q/apache-airflow_ffd1cf4f1898401783069c3840c181fd\r\n  fatal: unable to connect to github.com:\r\n  github.com[0: 192.30.255.113]: errno=Connection timed out\r\n\r\n\u001B[33mWARNING: Discarding git+git://github.com/databricks/incubator-airflow.git@1.8.1-db1#egg=apache-airflow[databricks]. Command errored out with exit status 128: git clone -q git://github.com/databricks/incubator-airflow.git /tmp/pip-install-rzbcv98q/apache-airflow_ffd1cf4f1898401783069c3840c181fd Check the logs for full command output.\u001B[0m\r\n\u001B[31mERROR: Could not find a version that satisfies the requirement apache-airflow (unavailable) (from versions: 1.10.9-bin, 1.8.1, 1.8.2rc1, 1.8.2, 1.9.0, 1.10.0, 1.10.1b1, 1.10.1rc2, 1.10.1, 1.10.2b2, 1.10.2rc1, 1.10.2rc2, 1.10.2rc3, 1.10.2, 1.10.3b1, 1.10.3b2, 1.10.3rc1, 1.10.3rc2, 1.10.3, 1.10.4b2, 1.10.4rc1, 1.10.4rc2, 1.10.4rc3, 1.10.4rc4, 1.10.4rc5, 1.10.4, 1.10.5rc1, 1.10.5, 1.10.6rc1, 1.10.6rc2, 1.10.6, 1.10.7rc1, 1.10.7rc2, 1.10.7rc3, 1.10.7, 1.10.8rc1, 1.10.8, 1.10.9rc1, 1.10.9, 1.10.10rc1, 1.10.10rc2, 1.10.10rc3, 1.10.10rc4, 1.10.10rc5, 1.10.10, 1.10.11rc1, 1.10.11rc2, 1.10.11, 1.10.12rc1, 1.10.12rc2, 1.10.12rc3, 1.10.12rc4, 1.10.12, 1.10.13rc1, 1.10.13, 1.10.14rc1, 1.10.14rc2, 1.10.14rc3, 1.10.14rc4, 1.10.14, 1.10.15rc1, 1.10.15, 2.0.0b1, 2.0.0b2, 2.0.0b3, 2.0.0rc1, 2.0.0rc2, 2.0.0rc3, 2.0.0, 2.0.1rc1, 2.0.1rc2, 2.0.1, 2.0.2rc1, 2.0.2, 2.1.0rc1, 2.1.0rc2, 2.1.0, 2.1.1rc1, 2.1.1, 2.1.2rc1, 2.1.2, 2.1.3rc1, 2.1.3, 2.1.4rc1, 2.1.4rc2, 2.1.4, 2.2.0b1, 2.2.0b2, 2.2.0rc1, 2.2.0, 2.2.1rc1, 2.2.1rc2, 2.2.1, 2.2.2rc1, 2.2.2rc2, 2.2.2, 2.2.3rc1, 2.2.3rc2, 2.2.3, 2.2.4rc1, 2.2.4, 2.2.5rc1, 2.2.5rc2, 2.2.5rc3, 2.2.5, 2.3.0b1, 2.3.0rc1, 2.3.0rc2, 2.3.0, 2.3.1rc1, 2.3.1, 2.3.2rc1, 2.3.2rc2, 2.3.2, 2.3.3rc1, 2.3.3rc2, 2.3.3rc3, 2.3.3, 2.3.4rc1, 2.3.4, 2.4.0b1, 2.4.0rc1, 2.4.0, 2.4.1rc1, 2.4.1, 2.4.2rc1, 2.4.2, 2.4.3rc1, 2.4.3, 2.5.0rc1, 2.5.0rc2, 2.5.0rc3, 2.5.0, 2.5.1rc1, 2.5.1rc2, 2.5.1, 2.5.2rc1, 2.5.2rc2, 2.5.2, 2.5.3rc1, 2.5.3rc2, 2.5.3, 2.6.0b1, 2.6.0rc1, 2.6.0rc2, 2.6.0rc3, 2.6.0rc4, 2.6.0rc5, 2.6.0, 2.6.1rc1, 2.6.1rc2, 2.6.1rc3, 2.6.1, 2.6.2rc1, 2.6.2rc2, 2.6.2, 2.6.3rc1, 2.6.3, 2.7.0b1, 2.7.0rc1, 2.7.0rc2, 2.7.0, 2.7.1rc1, 2.7.1rc2, 2.7.1, 2.7.2rc1, 2.7.2, 2.7.3rc1, 2.7.3, 2.8.0b1, 2.8.0rc1, 2.8.0rc2, 2.8.0rc3, 2.8.0rc4, 2.8.0, 2.8.1rc1, 2.8.1, 2.8.2rc1, 2.8.2rc2, 2.8.2rc3, 2.8.2)\u001B[0m\r\n\u001B[31mERROR: No matching distribution found for apache-airflow (unavailable)\u001B[0m\r\n\u001B[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\r\nYou should consider upgrading via the '/local_disk0/.ephemeral_nfs/envs/pythonEnv-687f8b5b-c86f-4da5-b3a6-14799763ab60/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "%sql\n",
    "select value, count(value) as total \n",
    "from output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68909b4f-d705-4dcc-a36a-c5e8e7910ec5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;36m  File \u001B[0;32m<command-1383676932774133>:1\u001B[0;36m\u001B[0m\n",
       "\u001B[0;31m    airflow initdb\u001B[0m\n",
       "\u001B[0m            ^\u001B[0m\n",
       "\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;36m  File \u001B[0;32m<command-1383676932774133>:1\u001B[0;36m\u001B[0m\n\u001B[0;31m    airflow initdb\u001B[0m\n\u001B[0m            ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n",
       "errorSummary": "<span class='ansi-red-fg'>SyntaxError</span>: invalid syntax (<command-1383676932774133>, line 1)",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c478821e-0068-474a-ba12-814d0976cbaf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[19]: '0301-050826-sctb0vx2'"
     ]
    }
   ],
   "source": [
    "#spark.conf.get(\"spark.databricks.clusterUsageTags.clusterName\")\n",
    "\n",
    "spark.conf.get(\"spark.databricks.clusterUsageTags.clusterId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ed8b23c-c03f-4cd0-b453-95b9d72c55c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-824783626057710>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mspark.databricks.clusterUsageTags.clusterKey\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/conf.py:49\u001B[0m, in \u001B[0;36mRuntimeConfig.get\u001B[0;34m(self, key, default)\u001B[0m\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkType(key, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkey\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m default \u001B[38;5;129;01mis\u001B[39;00m _NoValue:\n",
       "\u001B[0;32m---> 49\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jconf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m default \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:228\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    226\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdeco\u001B[39m(\u001B[38;5;241m*\u001B[39ma: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n",
       "\u001B[1;32m    227\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 228\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m    230\u001B[0m         converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n",
       "\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n",
       "\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n",
       "\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n",
       "\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n",
       "\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n",
       "\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n",
       "\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o761.get.\n",
       ": java.util.NoSuchElementException: spark.databricks.clusterUsageTags.clusterKey\n",
       "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.noSuchElementExceptionError(QueryExecutionErrors.scala:2310)\n",
       "\tat org.apache.spark.sql.internal.SQLConf.$anonfun$getConfString$4(SQLConf.scala:5346)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat org.apache.spark.sql.internal.SQLConf.$anonfun$getConfString$1(SQLConf.scala:5346)\n",
       "\tat com.databricks.spark.DatabricksSparkConf$AioaLazyConfigConf$.recordStringConfigAccessDuringWarmUp(DatabricksSparkConf.scala:1166)\n",
       "\tat org.apache.spark.sql.internal.SQLConf.getConfString(SQLConf.scala:5346)\n",
       "\tat org.apache.spark.sql.RuntimeConfig.get(RuntimeConfig.scala:88)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\nFile \u001B[0;32m<command-824783626057710>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mspark.databricks.clusterUsageTags.clusterKey\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/conf.py:49\u001B[0m, in \u001B[0;36mRuntimeConfig.get\u001B[0;34m(self, key, default)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkType(key, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkey\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m default \u001B[38;5;129;01mis\u001B[39;00m _NoValue:\n\u001B[0;32m---> 49\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jconf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m default \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:228\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdeco\u001B[39m(\u001B[38;5;241m*\u001B[39ma: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 228\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    230\u001B[0m         converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n\n\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o761.get.\n: java.util.NoSuchElementException: spark.databricks.clusterUsageTags.clusterKey\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.noSuchElementExceptionError(QueryExecutionErrors.scala:2310)\n\tat org.apache.spark.sql.internal.SQLConf.$anonfun$getConfString$4(SQLConf.scala:5346)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.internal.SQLConf.$anonfun$getConfString$1(SQLConf.scala:5346)\n\tat com.databricks.spark.DatabricksSparkConf$AioaLazyConfigConf$.recordStringConfigAccessDuringWarmUp(DatabricksSparkConf.scala:1166)\n\tat org.apache.spark.sql.internal.SQLConf.getConfString(SQLConf.scala:5346)\n\tat org.apache.spark.sql.RuntimeConfig.get(RuntimeConfig.scala:88)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n\tat java.lang.Thread.run(Thread.java:750)\n",
       "errorSummary": "java.util.NoSuchElementException: spark.databricks.clusterUsageTags.clusterKey",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.databricks.clusterUsageTags.clusterKey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46a868fc-1fdc-44a7-8a25-d3d75babe7e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [
    {
     "elements": [
      {
       "dashboardResultIndex": 0,
       "elementNUID": "16b4308b-cacb-4074-b5fd-349972e6c715",
       "elementType": "command",
       "guid": "a95ecd2b-4657-4871-9813-776784fc58dd",
       "options": null,
       "position": {
        "height": 6,
        "width": 12,
        "x": 0,
        "y": 0,
        "z": null
       },
       "resultIndex": null
      }
     ],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "bae553ea-6ebe-4ca2-9b1e-927d34b66713",
     "origId": 342828594733470,
     "title": "eda",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "TimeSeries_of_NYC_StockExchange",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
